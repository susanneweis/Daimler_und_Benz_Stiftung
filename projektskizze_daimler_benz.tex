
\documentclass[11pt,a4paper]{article}
\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
\usepackage{setspace}
\usepackage{parskip}
\usepackage{enumitem}
\usepackage{hyperref}
\usepackage{mathptmx} 
\usepackage{csquotes}
%\usepackage[backend=biber,style=apa]{biblatex}
\usepackage[backend=biber,style=numeric]{biblatex}
\renewcommand*{\bibfont}{\small}  % Schriftgröße der Referenzen
\usepackage{soul} % us hl to highlight
\usepackage{xcolor} % Optional, falls du die Farbe ändern willst
\usepackage[most]{tcolorbox}  % in der Präambel
\usepackage{titlesec}
\usepackage{changepage}
\usepackage{comment}
\usepackage{tabularx}
\usepackage[table]{xcolor} % Optional: für dezente Hintergrundfarben
\usepackage{booktabs}      % Für schönere Tabellenlinien
\usepackage{longtable}
\usepackage{array}
\usepackage[table]{xcolor}
\usepackage{graphicx}   % wichtig fürs Einfügen von Bildern
\usepackage{caption}    % erlaubt auch unnummerierte Captions (optional)
\usepackage{wrapfig}   % Text um Bilder herum
\captionsetup[figure]{name=Fig.}
\captionsetup[figure]{aboveskip=1pt, belowskip=-2ex}
\captionsetup[figure]{font={scriptsize,it}}

\usepackage{enumitem}   % <--- needed for aligned description lists
\usepackage{hyperref}   % for clickable email
\usepackage{calc}

% Vor der Tabelle:
\renewcommand{\arraystretch}{1.2}
\rowcolors{2}{gray!10}{white}

\titlespacing*{\section}{0pt}{0.8ex plus 0.5ex minus .2ex}{0.3ex}
\titlespacing*{\subsection}{0pt}{0.8ex plus 0.5ex minus .2ex}{0.3ex}
\titlespacing*{\subsubsection}{0pt}{0.8ex plus 0.5ex minus .2ex}{0.3ex}
\titleformat{\paragraph}[block]{\normalfont\normalsize\bfseries}{\theparagraph}{1em}{}
\titlespacing*{\paragraph}{0pt}{0.5ex plus 0.2ex minus 0.1ex}{1ex}

\sethlcolor{yellow} % Setzt die Highlight-Farbe
\setlist[itemize]{leftmargin=*, topsep=-3pt, itemsep=0pt}
\setstretch{1}

\addbibresource{Daimler.bib}

\begin{document}

\subsection*{Applicant} 
\vspace{1ex}
\textbf{PD Dr. Susanne Weis}\\
Group Leader "Brain Variability", Institute of Neuroscience and Medicine, Brain and Behaviour (INM-7), Research Centre Jülich, Jülich, Germany and \\
Institute of Systems Neuroscience, Medical Faculty, Heinrich Heine University Düsseldorf, Düsseldorf, Germany. \\
\textbf{Contact Details:} eMail: S.Weis@fz-juelich.de, phone: +49 2461 61 85925\\

\subsection*{Scientists and Institutions involved in the research project}
\vspace{1ex}
\textbf{Prof. Dr. Simon Eickhoff}\\
Institute of Neuroscience and Medicine, Brain and Behaviour (INM-7), Research Centre Jülich, Jülich, Germany and \\
Institute of Systems Neuroscience, Medical Faculty, Heinrich Heine University Düsseldorf, Düsseldorf, Germany. 

\textbf{Institute of Neuroscience and Medicine, Brain and Behaviour (INM-7)}, Research Centre Jülich, 
Jülich, Germany: \\
The proposed work is embedded in a multidisciplinary working team combining knowledge in the field of neuropsychology, structural and functional MRI analysis, 
computational neuroscience and machine learning. 


\newpage

\section*{\Large\textbf{Dynamic Cognition: Movies as a Window into Sex Differences in the Brain}}
\hfill

\subsection*{Project Description} 
\subsection*{Background and Research Question} 

Functional brain imaging, especially fMRI, has been widely used to investigate sex differences in the brain. 
Such differences in structural and functional brain organization are crucial for understanding healthy development, 
aging, and the manifestation of psychiatric and neurological disorders \parencite{cahillWhySexMatters2006,gobinathSexHormonesGenotype2017}. 
Thus, a deeper understanding of sex differences in the brain and their underlying mechanisms is essential 
for understanding both healthy behavior and psychopathology.\\
In this proposal, we employ novel brain imaging methodology utilizing naturalistic viewing (NV), i.e. watching movie 
clips in the scanner, to gain new perspectives on sex differences in brain function. While it is common knowledge 
that women and men often react differently to films, our study moves beyond stereotypes (“women prefer emotions, 
men prefer action”) to examine in detail how brain activity and functional connectivity (FC) differ when 
viewing diverse scenes. For example, women may process subtle social cues in dialogue in more depth, whereas 
men may respond more strongly to visual foreshadowing of danger. Through the novel use of NV fMRI, we aim to uncover 
sex-specific neural mechanisms that have remained invisible to traditional approaches, advancing the field far beyond 
the current state of research.\\
Classical studies used task-based (TB) fMRI, yielding domain-specific insights on cognitive sex differences. 
\parencite{thimmMenstrualCycleEffects2014a,weisDynamicChangesFunctional2011,weisEstradiolModulatesFunctional2008}. 
However, due to the highly artificial nature of the tasks, ecological validity of task-related fMRI is usually 
very low and does not reflect cognitive sex differences as observed in daily life.
More recently, resting-state (RS) fMRI has been applied, in which fMRI data is acquired while subjects relax 
in the scanner without any specific task demand or visual or auditory stimulation.
Earlier RS studies examined group differences in FC patterns between women and men. 
More recently, machine learning (ML) methods have been applied to move beyond group averages: 
sex classification approaches use RS data to predict the sex of individual subjects 
\begin{wrapfigure}{r}{0.3\textwidth} % r = rechts, l = links
  \vspace{-10pt} % optional: kleine Korrektur, damit es bündig startet
  \includegraphics[width=\linewidth]{sex_classification.png}
  \caption{ROI-based sex classification shows high accuracies for (a) within sample CV and (b) across sample classification.}
  \label{fig:sexclass}
\end{wrapfigure}
and then infer which brain networks contribute most to distinguishing females from males.
Our own ML work identified regionally specific networks with predictive power strongest in higher-level regions 
for language, social cognition, and emotion processing \parencite{weisSexClassificationResting2020a,wierschAccurateSexPrediction2023a,wierschSexDifferencesBrain2021a}.
However, RS primarily reflects intrinsic, trait-like brain organization. What remains largely unexplored are 
sex differences in the “brain in action” when engaging with complex, multimodal input resembling real life.\\ 
The present proposal aims to contribute to closing this gap in knowledge by applying the newly 
emerging NV approach to examine sex-specific brain responses in ecologically valid contexts. 
NV focuses on cognitive processes in dynamic, temporally extended, naturalistic contexts, much more akin to
situations which the brain must deal with in real life.
Importantly, as opposed to RS, all participants are exposed to the same stimulus, 
for which content and timing 
is known and can be used in the analyses.
\par\vspace{-\parskip}\noindent % small, controlled separation
Such approaches offer complex, dynamic, and ongoing stimulation similar to experiences in everyday life, 
where low-level (audiovisual) and high-level (cognitive and emotional) content vary fluidly, 
creating a multimodal immersive experience \parencite{sonkusareNaturalisticStimuliNeuroscience2019}. 
This provides the opportunity to capture dynamic neural processing in ecologically valid contexts 
\parencite{vanderwalMoviesMagnetNaturalistic2019} and has been shown to enhance reliability and identifiability 
over RS \parencite{krollNaturalisticViewingIncreases2023}.\\
Our lab has pioneered NV analyses. We developed the "Topography-based Predictive Framework" (TOPF) 
\parencite{liTopographybasedPredictiveFramework2023a}, which extracts individual-specific evoked 
topographies and links them to behavior using ML.
TOPF achieved up to 80\% accuracy in sex classification \parencite{liStimulusSelectionInfluences2025a}, 
with predictive regions tied to emotion, language, and higher cognition. 
These promising results highlight the potential of NV to uncover novel sex differences.\\
Surprisingly, to our knowledge, no study has yet used NV to systematically examine sex differences. 
In a previous publication \parencite{eickhoffClinicalApplicationsMovie2020a}, we have compared the potential of 
movies for the study of individual brain differences to a cardiac stress-test, 
i.e. to potentially provide a standardized way to study the whole organ while it works to compare function 
across different levels of intensity and demands. 
We therefore expect NV to expose sex differences across a wide range of real-life-like situations — social interactions, 
face and emotion perception \parencite{sonkusareNaturalisticStimuliNeuroscience2019}, 
or complex narratives - that TB or RS approaches cannot capture. 
While isolated cognitive processes as examined in TB fMRI might not reveal 
significant sex differences, the complex interplay of these processes - as engaged during movie watching - could 
highlight more pronounced differences between women and men. 
Careful stimulus annotation will further allow us to identify the specific features and networks driving these differences.
Using advanced neuroimaging and analysis methods, we aim to detect subtle but meaningful sex-related differences 
in brain activity and FC, that can inform our understanding of 
broader cognitive and behavioral differences between females and males.
To do so, we will first study FC patterns that are aggregated across the full duration of several minutes of movie watching. 
Then, we will zoom in to
identify specific events that trigger differences between women and men, and finally examine how differences in brain activity
unfold over time and in relation to the progressing content of the movies.\\
This multi-layered approach — combining aggregated and time-resolved FC, network dynamics, and brain activity — offers 
a rich view of sex differences in the brain function. 
Results from the proposed project can shed new light on why cognitive and behavioral patterns differ 
between women and men, and why certain neurological and psychiatric disorders present differently across the sexes. 
Such knowledge may improve diagnostic precision and personalized treatments, and support sex-specific 
strategies in healthcare and education.\\
We are uniquely positioned to realize this project, as our lab has already acquired the \textbf{Ju-MOVIES dataset}, 
a rich NV fMRI resource with over 130 participants. It combines extended movie stimuli, 
hormone measures, and detailed scene annotations, providing an unparalleled foundation for 
uncovering sex differences in the brain.\\
For clarity, throughout this proposal “sex” refers to self-reported biological sex. 
We acknowledge that “gender identity”, i.e. the 
subjective identification of an individual as female, male, or one of the other gender identities which might 
be also fluid, also plays a significant role, but this lies 
beyond the scope of the present project.

\subsection*{Data: The Ju-MOVIES dataset}
The proposed work builds on the Ju-MOVIES dataset, which has already been acquired and is 
uniquely suited for investigating sex differences with a NV approach. Its richness and design make it an ideal 
foundation for the present project, which will be further expanded over the course of the proposed project. 
The paradigm comprises seven Hollywood movie excerpts (8 - 10 minutes each) selected to capture diverse social 
interactions, complex situations, and evolving emotions (“Dirty Dancing”, “Scream”, “Dead Poets Society”, “Forrest Gump”, “Dead Man Walking”, “Life is Beautiful”, 
“The Good, the Bad, the Ugly”), as well as 12 shorter clips and two RS scans of about 9 minutes.
Stimuli were chosen to be long enough for participants to grasp the context and empathize with characters, 
ensuring ecological validity.\\
So far, data from 135 healthy participants (68 males, 18 - 35 years) have been collected 
on a 3T Siemens Prisma scanner
with a 64-channel head coil, using a T2w multiband echo planar imaging sequence with the 
following parameters: repetition time (TR) = 980ms, echo time (TE) = 30ms, flip angle = 70°, field of view 
(FOV) = 207 x 207mm, voxel size=2.2 x 2.2 x 2.0mm3, number of slices: 64, multiband acceleration factor=4, 
phase encoding direction=AP,  FoV=207mm). A mirror fixed on the head coil allows participants to see a screen used 
to display the movies. In-ear headphones are used for ear protection and to deliver the movie sound. 
Additionally, a structural T1w image is acquired using an MP-RAGE sequence (TR=2000ms, TE=2.45ms, TI=900ms, 
flip angle=8°, FoV: 256mm) yielding 1mm3 voxels.
Alongside fMRI and structural imaging, saliva samples were collected and analyzed for levels of cortisol, estradiol, progesterone,
\begin{wrapfigure}{r}{0.27\textwidth} % r = rechts, l = links
  \vspace{-10pt} % optional: kleine Korrektur, damit es bündig startet
  \includegraphics[width=\linewidth]{emotions_DMW_edited.png}
  \caption{Exemplary emotion annotation for one of the movie stimuli..}
  \label{fig:dmw}
\end{wrapfigure}
 and testosterone to account for hormone-related variability. 
Oral contraceptive use was documented in women.
The movies are richly annotated: 
emotion ratings from 44 additional participants (23 males, age 20-30 years)
for the six basic emotions (happiness, fear, surprise, sadness, disgust and anger \parencite{ekmanConstantsCulturesFace1971a}), 
sampled at 10 Hz confirmed that the stimuli evoke a wide spectrum of affective states. 
Further annotations by two independent raters include scene content: faces, bodies, male / female presenting characters, ethnicity of characters, presence of children, 
adults, crowds, hands, buildings, vehicles, food, landscapes, animals, plants, movement, social interactions, 
place (inside or outside / urban vs. non-urban), time of day (day or night), weather, presence of music and 
camera movements, enabling fine-grained mapping of movie features to neural responses.
Altogether, Ju-MOVIES offers a rare combination of naturalistic stimulation, hormone measures, 
and detailed scene-level annotations, providing an exceptionally strong basis for the proposed project.

\subsection*{Work Program and Research Methods}
The overarching goal of the proposed project is to complement existing research on sex differences in the brain by 
employing a NV approach. This method promises new insights into sex differences in brain responses to complex, 
dynamically evolving situations—much closer to the demands the brain faces in real life. Our results can go beyond 
findings from both TB and RS studies and provide perspectives that previous approaches could not achieve. 
Specifically, we will identify which types of complex situations depicted in the movie stimuli give rise to the 
most pronounced sex differences. In subsequent steps, we will disentangle which narrative events within the 
movies drive these differences and examine how female and male brains respond differentially to the evolving storyline. 
We expect that this innovative approach, combining analyses of temporally aggregated 
FC, event-related responses, network dynamics and brain activity will yield important new insights into 
the multi-faceted spectrum of sex differences in the brain in action.\\
\textbf{WP1} will extend existing RS findings by examining sustained FC during NV across time periods of several 
minutes. Using a temporally aggregated FC approach, as commonly applied to RS data, this work will identify 
sex differences in “action brain states” and their underlying networks.\\
\textbf{WP2} will build on findings from \textbf{WP1} by employing a time-resolved FC approach to detect temporally specific events 
that drive sex differences in the experience of complex situations. Leveraging detailed annotations of the 
movie content, we will characterize which types of situations give rise to pronounced sex differences and 
reveal sex-specific cognitive strategies in processing them.\\
\textbf{WP3} will examine brain activation patterns rather than FC, identifying how typical female and male 
brain responses emerge during the evolving movie narratives. This analysis will 
complement \textbf{WP1} and \textbf{WP2} by capturing how women's and men's brains differentially respond 
to unfolding narrative events.

\subsection*{WP 1: Beyond Resting State - Sustained Action States in Naturalistic Viewing}

\textbf{Aim:} Identify sex differences in sustained, content-driven brain “action states” during NV 
and compare their predictive power against RS connectivity.

\textbf{Open Question:} Do sex-specific movie feature networks differ systematically, and if so, 
what do these differences reveal about distinct cognitive strategies in women and men?  

RS studies have demonstrated that sex can be classified with high accuracy based FC patterns that are 
aggregated across time \parencite{casanovaCombiningGraphMachine2012a,ritchieSexDifferencesAdult2018,weisSexClassificationResting2020a,wierschAccurateSexPrediction2023a,wierschSexDifferencesBrain2021a}. 
Because RS measures brain activity in the absence of external stimulation, these connectivity patterns are 
typically interpreted as indicators of intrinsic brain organization—capturing stable, trait-like characteristics 
rather than momentary states.\\
In this \textbf{WP}, we go beyond RS by studying sustained FC patterns evoked by complex movie narratives. 
Unlike RS, these naturalistic viewing action states (NV-ASs) are driven by the actual content of the films, 
meaning that the brain's functional organization adapts continuously to what happens on screen. Since the content is precisely 
defined and the timing is identical for all participants, we can directly link FC patterns to narrative features and identify
sex-specific differences in how these states unfold. This \textbf{WP} will therefore provide insights into which kinds of complex, 
real-life-like situations give rise to the most pronounced sex differences in brain networks. By focusing on the brain “in action,” 
we aim to capture sex differences in the holistic experience of complex situations—an approach that is fundamentally different 
from both TB studies, which focus on isolated cognitive processes, and RS studies, which mainly reflect 
intrinsic brain organization during unconstrained thought. \\
We hypothesize that putting the brain into action will bring sex differences into sharper relief 
than the unconstrained state of mind wandering \parencite{vanderwalIndividualDifferencesFunctional2017}.\\
From a methodological perspective, we will build on and extend our previously developed sex classification 
framework \parencite{weisSexClassificationResting2020a}. Specifically, fMRI data will be divided 
into non-overlapping brain regions using an established parcellation scheme \parencite{schaeferLocalGlobalParcellationHuman2018}. 
For each region, a representative time course will be extracted, and functional connectivity with all other regions will be calculated. 
These connectivity patterns will then serve as input features for sex classification using a cross-validation (CV) approach, 
resulting in a spatial map of classification accuracies for both RS and each NV-AS (i.e., each movie).
Importantly, and in contrast to most previous studies, we will explicitly incorporate hormone levels and oral contraceptive (OC) 
status in women as confounding variables in all prediction analyses. This ensures that the observed effects truly reflect 
sex differences rather than hormone-related variability. In addition, we will implement rigorous measures to avoid 
“confound leakage” \parencite{hamdanConfoundleakageConfoundRemoval2022a}, which can otherwise bias results. 
Taken together, these methodological precautions will guarantee robust, reliable, and unbiased findings.

\subsubsection*{WP 1.1:  Comparing sex classification accuracies between RS and NV-ASs}
As a first step, we will compare sex classification performance between RS and NV-AS (averaged across all movies) within each parcel, 
using corrected resampled \textit{t}-tests \parencite{nadeauInferenceGeneralizationError2003a}. 
If classification accuracies are higher during NV-AS than during RS, this would indicate that sex differences 
become more pronounced when the brain is “in action” rather than at rest.\\
Beyond overall accuracy, we will examine the spatial distribution of parcels that are most discriminative in NV-AS, 
thereby highlighting the brain networks that drive these differences. To better interpret their functional relevance, 
the identified networks will be characterized using functional decoding \parencite{foxMetaanalysisHumanNeuroimaging2014a}.\\
Previous RS studies have often reported sex differences in the default mode network (DMN) 
\parencite{weisSexClassificationResting2020a,zhangFunctionalConnectivityPredicts2018}. 
For NV-AS, however, we expect to observe effects in higher-order cognitive or task-general networks 
\parencite{hugdahlExistenceGeneralizedNonspecific2015a}. Moreover, we hypothesize that sex classification based on 
NV-AS will outperform RS, in line with findings for other 
phenotypes \parencite{finnCanBrainState2017a,vanderwalIndividualDifferencesFunctional2017} and with recent 
evidence that NV improves individual identifiability compared to RS \parencite{krollNaturalisticViewingIncreases2023}.

\subsubsection*{WP 1.2: Which movie features drive sex classification accuracies?}
To investigate which types of complex situations maximize sex differences in the brain, we will characterize each movie clip by a 
comprehensive set of visual and auditory features across its entire duration. These will include low-level 
properties such as mean motion energy, visual brightness, and auditory loudness, as well as higher-level properties such as the 
number of faces, social interactions, and spoken words. Many of these features can be automatically 
extracted \parencite{mcnamaraDevelopingComprehensiveFramework2017a,radfordRobustSpeechRecognition2022}, while others will come 
from our detailed manual annotations.\\
Next, we will apply a multiple regression approach to compare sex classification accuracies across the whole brain between 
different movie clips. This analysis will identify which movie features are most predictive for 
classification performance within each brain parcel. Because higher accuracy indicates more pronounced sex differences, 
the procedure will generate a “movie feature profile” that highlights which specific features evoke the strongest differences.\\
By clustering parcels according to their feature profiles, we will uncover brain networks in which sex differences are jointly 
driven by particular features. We hypothesize that some of these networks will map onto well-established cognitive domains such as 
language or spatial cognition \parencite{halpernSexDifferencesCognitive2000a,kimuraSexCognition2000a}, while others will 
reflect more generalized, task-independent resources \parencite{hugdahlExistenceGeneralizedNonspecific2015a}. 
We expect that domain-specific networks will generally achieve higher classification accuracies than domain-general ones.\\
Finally, in an exploratory step, we will directly compare the expression of these networks between women and men. 
By computing the first principal component of each network's FC pattern separately for females and males, we will 
derive “typical” female and male network signatures for each movie feature cluster. This will allow us to identify 
sex-specific cognitive strategies for processing complex, life-like situations.

\subsection*{WP 2: Going dynamic: Sex differences in time-resolved FC}

\textbf{Aim:} Determine which specific narrative events drive sex differences in FC 
and reveal sex-specific cognitive strategies in processing complex situations.  

\textbf{Open Questions:} How do naturalistic sex differences observed here relate to findings 
from traditional TB paradigms (e.g., isolated face viewing)? Do the same brain regions emerge, 
or do new networks appear under ecologically valid conditions?  

While \textbf{WP1} examines sex differences in sustained “action states” evoked by movies, 
\textbf{WP3} takes advantage of one of the main strengths of naturalistic viewing: its continuous, 
dynamic variation in content. Unlike RS or aggregated NV-AS analyses, here the goal is to dissect 
the evolving brain responses to specific narrative events within the movies. 
Because all participants experience the same time-locked stimulus, the impact of movie content on the 
brain can be examined directly and with temporal precision. This enables us to move beyond asking whether 
men and women differ \textit{on average} in their processing of complex situations, and 
instead pinpoint exactly \textit{which moments} in the evolving narrative trigger sex-specific brain network configurations. 
In other words, this \textbf{WP} shifts the focus from “what kind of situations” (\textbf{WP1}) to “exactly when and how” 
sex differences manifest during real-life-like experiences.\\  
Methodologically, fMRI data will again be parcellated, and parcel-wise time courses used to compute 
moment-by-moment co-fluctuations between regions using the edge time series (eTS) approach 
\parencite{betzelLivingEdgeNetwork2023,faskowitzEdgecentricFunctionalNetwork2020a}. 
This effectively “unwraps” FC into its temporal evolution, yielding a time series of 
co-fluctuation magnitudes for each edge.\\
To identify dynamic FC differences between females and males during movie watching, we will identify
time points within the movies, at which females' and males' FC patterns are most distinct. To do so, we
will employ a ML approach at each time point to classify sex based on the individual time resolved FC
patterns. Given that the dimensionality of these features, i.e. the number of edges, is extremely high, we
will first employ a principle commponent analysis (PCA) for dimensionality reduction. Then, for each time
point, the first n (e.g. 50) principal components will be used as features to train a sex classifier for which
classification accuracy will be determined by use of a CV approach. Again, hormone levels and OC status
will be included in the models as confounds to control for hormone related variability and possible confound
leakage will be assessed and controlled for \parencite{hamdanConfoundleakageConfoundRemoval2022a}.\\
Significant time points — those at which classification exceeds chance level (p < 0.05 by permutation test) — will be 
taken as markers of narrative events that drive the strongest sex differences. 
To characterize these events, movie annotations will be used to code the presence of discrete features 
(e.g., faces, bodies, animals, scene cuts) and continuous features (e.g., luminance, audio intensity). 
Each significant time point will thus be linked to a detailed movie feature vector.  
We will then cluster significant time points across movies according to their feature vectors, 
thereby identifying categories of scenes that consistently evoke sex-specific differences. 
For each cluster, typical female and male FC patterns will be computed as the first principal component 
across participants, and thresholded to highlight the most discriminative connections and key network nodes, allowing us 
to identify brain networks that respond differently in women and men to particular 
types of NV events.\\
Altogether, \textbf{WP2} will reveal which narrative elements most strongly drive sex differences in time-resolved 
FC and how these differences are expressed at the network level. 
While some of the observed patterns are expected to overlap with domains already known from TB studies 
(e.g., sex differences in face perception), this dynamic, ecologically valid approach will provide a 
much richer picture — capturing sex-specific strategies for processing complex, multimodal real-life situations.
Sex specific brain network patterns will potentially shed light on different cognitive strategies used by
females in males in dealing with complex real life-like events.   

\subsection*{WP 3: Shared but Unique: Examining Sex-Specific Responses to Dynamic Emotions}

\textbf{Aim:} To characterize how female and male brains differ in their regional activation patterns 
to evolving movie content, complementing connectivity-based analyses from \textbf{WP1} and \textbf{WP2}.  

\textbf{Open Questions:} Which brain regions display distinct time-resolved responses to emotional content in 
women and men, and are these effects stable across movie narratives? Do particular emotions (e.g., fear, anger, happiness) 
disproportionately trigger divergent neural activity between the sexes? 

A major advantage of NV paradigms over RS is that all participants are exposed to the same stimulus, 
producing synchronized neural responses across individuals, while still preserving meaningful inter-individual 
differences \parencite{finnIdiosynchronySharedResponses2020a,vanderwalIndividualDifferencesFunctional2017}. 
This \textbf{WP} capitalizes on that property to focus directly on the evolution of neural activation patterns 
during movie watching, asking whether and how females' and males' brains differ in their responses 
to dynamic, emotionally rich content. Since movies are especially effective in eliciting 
strong emotions \parencite{grossEmotionElicitationUsing1995,westermannRelativeEffectivenessValidity1996}, 
and sex differences in emotion perception and regulation are well documented 
\parencite{domesNeuralCorrelatesSex2010a,gardenerSexDifferencesEmotion2013a}, 
we focus here on differences in emotional brain responses unfolding over naturalistic narratives. 
This extends prior work that typically examined only isolated emotions in artificial tasks.\\  
Methodologically, we will employ the \textbf{Topography-based Predictive Framework (TOPF)} recently 
developed in our lab \parencite{liTopographybasedPredictiveFramework2023a}. For each brain region, 
TOPF extracts the shared time course of brain responses across participants (via PCA) and quantifies how 
strongly each individual expresses this response. In the present context, we will compute separate 
shared response time courses for women and men, while regressing out hormone levels to ensure that 
results reflect sex differences rather than hormone-driven variability.\\ 
Analyses will proceed in two steps. Firstly, we will directly compare the typical female and male time courses 
for each brain region to identify regions where the evoked responses fundamentally diverge between sexes. 
To probe whether such differences are driven by emotions depicted in the movies, we will correlate the 
sex-specific shared response with existing emotion annotations (six basic emotions). 
High correlations with particular emotions (e.g., fear, happiness) will reveal which emotions most 
strongly drive sex differences.\\
Second, for regions where overall time courses do not differ significantly, we will test whether the \textit{intensity} of 
response expression differs between the sexes using two-sample \textit{t}-tests, identifying regions in which 
females and males process the narrative similarly in form but differently in strength. 
Such regions are expected mainly in higher-order cognitive areas, and functional decoding will be
used to interpret their domain-specific relevance \parencite{foxMetaanalysisHumanNeuroimaging2014a}.\\  
Finally, we will assess whether whole-brain patterns reveal sex-typical processing of dynamic narratives. 
For each subject, we will compute the similarity of their brain response to the sex-specific shared response 
across all regions, and classify subjects accordingly. High classification accuracy would indicate 
the existence of typical female and male whole-brain response patterns; failure to classify would 
suggest that individual variability outweighs sex as the organizing principle.\\
Altogehter, \textbf{WP3} will identify sex-specific regional and whole-brain patterns in the perception of 
dynamic emotions, providing novel insights into how women and men process emotionally charged, 
real-life-like situations.\\  
[6pt]
In sum, by combining novel NV paradigms with state-of-the-art neuroimaging and analysis methods, 
this project moves beyond traditional approaches and opens a new path for understanding sex differences 
in the human brain. Leveraging our unique Ju-MOVIES dataset, we will reveal how female and male brains engage 
with the complexity of real-life-like experiences as they unfold on screen.
In doing so, we aim not only to advance basic neuroscience, 
but also to lay the groundwork for a future in which insights into sex-specific brain 
function help shape more precise diagnostics, personalized treatments, and ultimately more equitable 
strategies in medicine, education, and mental health.

\newpage

\subsection*{Requested Budget}

\noindent\textbf{Total: 145.860 Euro}

\begin{longtable}{p{12cm} p{\dimexpr\textwidth-12cm-2\tabcolsep}}
\toprule
\endfirsthead
\endhead
Costs for personnel (1 Doctoral Researcher (65\%) for 33 months \\ 33 * 6.800 * 0.65) & 145.860 Euro \\
\bottomrule
\end{longtable}

In case of funding of the present proposal, the institute commits to covering the doctoral researcher's remaining three 
months of salary to complete a full three-year position as well as the costs for ongoing fMRI scanning, 
with a corresponding letter of intent attached.\\

\newpage

\printbibliography

\end{document}
